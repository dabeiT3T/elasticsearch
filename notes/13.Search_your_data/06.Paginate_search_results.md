## Paginate search results

默认，搜索返回最匹配的 10 项。对大结果集进行分页，可以使用 search API 的 `from` 和 `size` 参数。`from` 参数定义要跳过多少项，默认 `0`。`size` 参数是返回命中项的最大数目，这两个参数定义了一页的结果。

```
GET /_search
{
  "from": 5,
  "size": 20,
  "query": {
    "match": {
      "user.id": "kimchy"
    }
  }
}
```

避免在使用 `from` 和 `size` 时分页太深或者一次请求太多结果。搜索请求通常跨多个分片。每个分片需要将请求命中的和之前页命中的加载到内存中。对于深页数和大结果集，这些操作会显著地增加内存和 CPU 的使用量，可能导致性能下降或节点故障。

默认，不可以使用 `from` 和 `size` 分页展示超过 10000 个匹配项。这个限制是索引设置 `index.max_result_window` 中的保护措施。如果需要分页展示超过 10000 项，使用 `search_after` 代替。

> Elasticsearch 使用 Lucene 内部文档 id 作为关键因素（tie-breakers）。相同数据的副本之间，这些内部文档 id 可能完全不同。再进行分页搜索时，可能偶尔会看到具有相同排序值的文档排序不一致。
>
> *即值都等 x 的两项在两次分页请求中可能交换顺序。*

### Search after

可以使用 `search_after` 参数使用一组来自前页的排序值检索下一页的匹配项。

使用 `search_after` 的多条搜索请求需要携带相同的 `query` 和 `sort` 值。如果在这些请求中发生一次更新操作，搜索结果可能发生改变，导致页面之间的结果不一致。为防止该情况发生，可以创一个时间点（point in time，PIT）来保存搜索的当前索引状态。

```
POST /my-index-000001/_pit?keep_alive=1m
```

接口返回一个 PIT ID。

```json
{
  "id": "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA=="
}
```

提交一个带有 `sort` 参数的搜索请求来获取第一页结果。如果使用 PIT，在 `pit.id` 参数中提供 PID ID，在请求路径中忽略目标数据流或索引。

*直接请求 `_search` 即可，提供索引会报错。*

> 所有 PIT 查询请求都会添加一个隐式的排序关键（tiebreaker）字段 `_shard_doc`，同样可以显式提供。如果无法使用 PIT，建议在 `sort` 中包含一个关键字段。对于每个文档，这个关键字段应该包含一个唯一值。否则，分页结果可能丢失或有重复的匹配。
>
> 当排序顺序为 `_shard_doc` 且不跟踪总命中数时，search after 请求优化过可以更快。如果想要遍历整个文档而不管顺序，这个最高效的选项。
>
> 如果 `sort` 字段在某些目标数据流或索引中的 `date` 但 在其它目标中为 `date_nanos`，使用 `numeric_type` 参数将值转化为单一的精度，并给 `sort` 字段指定日期格式。否则，`es` 将无法在每个请求中正确地解释 search after 的参数。

```
GET /_search
{
  "size": 10000,
  "query": {
    "match" : {
      "user.id" : "elkbee"
    }
  },
  "pit": {
    "id":  "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==", 	// 搜索的 PIT ID
    "keep_alive": "1m"
  },
  "sort": [    // 通过隐式的因素 _shard_doc 降序来排序搜索结果
    {"@timestamp": {"order": "asc", "format": "strict_date_optional_time_nanos", "numeric_type" : "date_nanos" }}
  ]
}
```

搜索响应中每个命中都包含一个 `sort` 值的数组。如果使用 PIT，每个命中的 `sort` 值的最后一项将包含一个关键因素。使用 PIT，称为 `_shard_doc` 的关键因素自动加入每一个搜索请求。`_shard_doc` 值由 PIT 中的分片索引和 Lucene 的内部 doc ID 组合而成。同样可以显式地将关键因素加入搜索请求中，自定义顺序：

```
GET /_search
{
  "size": 10000,
  "query": {
    "match" : {
      "user.id" : "elkbee"
    }
  },
  "pit": {
    "id":  "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==",  // 搜索的 PIT ID
    "keep_alive": "1m"
  },
  "sort": [  // 通过显式的因素 _shard_doc 降序来排序搜索结果
    {"@timestamp": {"order": "asc", "format": "strict_date_optional_time_nanos"}},
    {"_shard_doc": "desc"}
  ]
}
```

```json
{
  "pit_id" : "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==", // 更新了的 PIT ID
  "took" : 17,
  "timed_out" : false,
  "_shards" : "...",
  "hits" : {
    "total" : "...",
    "max_score" : null,
    "hits" : [
      {
        "_index" : "my-index-000001",
        "_id" : "FaslK3QBySSL_rrj9zM5",
        "_score" : null,
        "_source" : "...",
        "sort" : [          // 上一次返回命中的排序值
          "2021-05-20T05:30:04.832Z",
          4294967298        //  因素值，在 `pit_id` 中每个文档都有唯一值
        ]
      }
    ]
  }
}
```

*注意由于按照自定义排序，所以全文索引搜索的评分失效了；如果在 `sort` 仅仅指定按照评分排序（没有 PIT），则响应中没有返回 `sort`，可能是因为需要 `sort` 值为唯一值时才有效。*

*使用 `search_after` 时需要使用 `_score` 分页时，需要使用 `_score` 作为主排序顺序，可以使用 `_id`（唯一值）作为第二排序顺序。如果两个文档有相同分，那么它们会按照 `_id` 排序。*

```json
"sort": [
  {"_score": {"order": "desc"}},
  {"_id": {"order": "asc"}}
]
```

*但是在 `_id` 上进行排序并不是推荐的，因为在该字段上文档值无效（`text` 应该不支持）；结果可能造成内存泄漏。可以将 `_id` 的值拷贝到一个其它字段（例如整型），将新字段作为关键因素。*

```json
"sort": [
  {"_score": {"order": "desc"}},
  {"primary_id": {"order": "asc"}}
]
```

**阿里云 7.10 版本没有 `_shard_doc` 字段。**

获取下一页的结果，使用上一次命中的排序值（包含关键因素）作为 `search_after` 参数，重新运行上次搜索。如果还使用了 PIT，将最新的 PIT ID 放入 `pit.id` 参数。搜索的 `query` 和 `sort` 参数必须保持不变。如果提供 `from` 参数必须为 0（默认）或 `-1`。

```
GET /_search
{
  "size": 10000,
  "query": {
    "match" : {
      "user.id" : "elkbee"
    }
  },
  "pit": {
    "id":  "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA==", // 上次请求返回的 PIT ID
    "keep_alive": "1m"
  },
  "sort": [
    {"@timestamp": {"order": "asc", "format": "strict_date_optional_time_nanos"}}
  ],
  "search_after": [ // 上次请求最后命中的排序值
    "2021-05-20T05:30:04.832Z",
    4294967298
  ],
  "track_total_hits": false    // 关闭追踪命中总数以提高分页速度
}
```

重复此过程以获得额外的结果页。如果使用 PIT，可以在每个搜索请求中使用 `keep_alive` 参数延长 PIT 的有效期。

完成后，需要删除 PIT。

```
DELETE /_pit
{
    "id" : "46ToAwMDaWR5BXV1aWQyKwZub2RlXzMAAAAAAAAAACoBYwADaWR4BXV1aWQxAgZub2RlXzEAAAAAAAAAAAEBYQADaWR5BXV1aWQyKgZub2RlXzIAAAAAAAAAAAwBYgACBXV1aWQyAAAFdXVpZDEAAQltYXRjaF9hbGw_gAAAAA=="
}
```

### Scroll search results

> 不再推荐使用 scroll API 进行深度分页。如果需要在分页超过 10000 次命中时保持索引状态，`search_after` 参数和时间点（PIT）一起使用。

尽管 `search` 请求返回结果的单 ”页“，`scroll` API 可以用来在单词搜索请求中获取大量的结果（甚至全部），非常像在传统数据库中使用的游标。

滚动（Scroll）不是用于实时用户请求，而是用于处理大量数据。例如，为了将一个数据流或索引的内容重新索引到具有不同配置的新数据流或索引中。

> 滚动请求返回的结果反映了发出开始 `search` 搜索请求时数据流或索引的状态，就像时间快照一样。对文档的后需更改（索引，更新或删除）只会影响以后的搜索请求。

为了使用滚动，开始的搜索请求应该在查询字符串中指定 `scroll` 参数；这告诉 `es` 应该保持 ”搜索上下文（search context）“ 的有效期时间。例如 `?scroll=1m`。

```
POST /my-index-000001/_search?scroll=1m
{
  "size": 100,
  "query": {
    "match": {
      "message": "foo"
    }
  }
}
```

上方请求的结果包含 `_scroll_id`，需要将其传给 `scroll` API 来获取下一批结果。

```
POST /_search/scroll
{
  "scroll" : "1m",                                                             
  "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==" 
}
```

1. 可以使用 `GET` 或 `POST`，连接中不应该包含 `index` 名字——在源 `search` 请求中已经指定了。
2. `scroll` 参数告诉 `es` 继续保持搜索上下文有效 `1m`。
3. `scroll_id` 参数

`size` 参数可以设置每一批返回结果的最大命中数。每一个 `scroll` API 的请求返回下一批结果，直到没有剩余结果返回，即 `hits` 空数组。

> 开始的搜索请求和每个后来的滚动请求都返回一个 `_scroll_id`。尽管在请求之间 `_scroll_id` 可能会改变，但通常不会变化——在任何情况下，只应该使用最近收到的 `_scroll_id`。
>
> 如果请求指定聚合，只有开始的搜索请求会包含聚合结果。
>
> 当排序顺序是 `_doc` 时，滚动请求被优化得更快。如果需要遍历所有文档而不考虑顺序，这是最有效的选项：

```
GET /_search?scroll=1m
{
  "sort": [
    "_doc"
  ]
}
```

#### Keeping the search context alive

滚动返回搜索请求开始时间点的所有文档。忽略对这些文档的后续改变。`scroll_id` 标识了一个搜索上下文，保持追踪 `es` 确保返回正确的文档。搜索上下文通过最初的请求创建并在后续请求中保持有效。

`scroll` 参数（传给 `search` 请求和每个 `scroll` 请求）告诉 `es` 需要保持搜索上下有效多久。该值（例如 `1m`）不需要足够长到运行所有数据——只需要够运行先前批次的结果。每个 `scroll` 请求（携带 `scroll` 参数）设置一个新的过期时间。如果一个滚动请求没有没有传入 `scroll` 参数，搜索上下文将被释放，作为滚动请求的一部分。

通常，后台合并过程通过较小的段来优化索引，以创建新的更大的段。一旦较小的片段不再需要，它们就被删除。这一过程在滚动期间持续，但是一个开启的搜索上下文会阻止旧段被删除，因为它们仍然在使用中。

> 保持较旧的段为活动状态意味着需要更多的磁盘空间和文件句柄。确保已将节点配置为有足够的空闲的文件句柄。

此外，如果一个分段包含已删除或更新的文档，那么搜索上下文必须跟踪段中的每个文档在最初的搜索请求时是否处于活动状态。如果在一个索引上有许多打开的滚动，且该索引遭受不断的删除和更新，那么需要确保节点有足够的堆空间。

> 为了防止过多的滚动开启导致的问题，不允许用户开启滚动的数量超过一定的限制。默认最大的滚动开启数是 500。可以通过 `search.max_open_scroll_context` 集群设置修改这一限制。

可以通过 nodes stats API 查看开启了多少搜索上下文：

```
GET /_nodes/stats/indices/search
```

#### Clear scroll

当 `scroll` 超时到达时，搜索上下文会自动删除。然后保持滚动开启需要成本，就像上节讨论的。一旦滚动不再需要使用就应该显式地使用 `clear-scroll` API 清理：

```
DELETE /_search/scroll
{
  "scroll_id" : "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ=="
}
```

多个滚动 ID 可以作为数据传入：

```
DELETE /_search/scroll
{
  "scroll_id" : [
    "DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==",
    "DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB"
  ]
}
```

使用 `_all` 参数清理所有的搜索上下文：

```
DELETE /_search/scroll/_all
```

`scroll_id` 可以通过查询字符串参数或者请求体中传入。多个滚动 ID 可以通过逗号分隔传入：

```
DELETE /_search/scroll/DXF1ZXJ5QW5kRmV0Y2gBAAAAAAAAAD4WYm9laVYtZndUQlNsdDcwakFMNjU1QQ==,DnF1ZXJ5VGhlbkZldGNoBQAAAAAAAAABFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAAAxZrUllkUVlCa1NqNmRMaUhiQlZkMWFBAAAAAAAAAAIWa1JZZFFZQmtTajZkTGlIYkJWZDFhQQAAAAAAAAAFFmtSWWRRWUJrU2o2ZExpSGJCVmQxYUEAAAAAAAAABBZrUllkUVlCa1NqNmRMaUhiQlZkMWFB
```

#### Sliced scroll

当对当量文档进行分页时，将搜索拆分为多个片以独立地使用会很有帮助：

```
GET /my-index-000001/_search?scroll=1m
{
  "slice": {
    "id": 0,                      
    "max": 2                      
  },
  "query": {
    "match": {
      "message": "foo"
    }
  }
}

GET /my-index-000001/_search?scroll=1m
{
  "slice": {
    "id": 1,
    "max": 2
  },
  "query": {
    "match": {
      "message": "foo"
    }
  }
}
```

1. `slice.id` 是分片的 id
2. `slice.max` 分片的最大数

第一个请求的结果返回属于第一个分片（id: 0）的文档，第二个请求的结果返回属于第二个分片的文档。由于最大分片数是 2，两个请求的结果并集等于不分片的滚动查询。默认情况下，首先在分片上进行分割，然后使用 `_id` 字段在每个分片上本地进行分隔。本地分割遵循方程式 `slice(doc) = floorMod(hashCode(doc._id), max)`。

每个滚动是独立的，可以并行地像任何滚动请求一样执行。

> 如果分片（slice）数量大于文档的分片（shard）数量，第一次请求时分片筛选器将非常缓慢。复杂度为 O(N) 并且每个分片的内存花销等于 N 位。N 是分片（shard）中文档的总数量。少量调用后，筛选器会缓存，后续的请求会快一些，但是应该限制并行执行的分片的查询，避免内存爆炸。

时间点（point-in-time）API 支持更有效的分区策略，不会遇到这个问题。可能时，推荐使用时间点搜索来分片而不是滚动。

另一个避免这样高开销的方法是使用另一个字段的 `doc_values` 来分片。该字段必须具有以下特性：

- 字段是数字。
- 该字段开启了 `doc_values`
- 每个文档需要包含一个单值。如果文档的指定字段有多个值，会使用第一个值。
- 每个文档的值应该在创建文档时设置一次，且永不更新。这确保了每个分片都能得到确定的结果。
- 字段的基数要高一些。确保每个分片（slice）获得的文档数量大致相同。*感觉用 shard 合理一些。*

```
GET /my-index-000001/_search?scroll=1m
{
  "slice": {
    "field": "@timestamp",
    "id": 0,
    "max": 10
  },
  "query": {
    "match": {
      "message": "foo"
    }
  }
}
```

对于仅追加基于时间的索引，`timestamp` 字段可以安全地使用。
