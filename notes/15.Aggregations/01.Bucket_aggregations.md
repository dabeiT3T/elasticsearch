## Bucket aggregations

桶聚合不像维度聚合（metrics aggregations）那样计算字段上的维度，它创建文档的桶。每个桶关联一个尺度（根据聚合的类型），决定当前上下文中的文档是否被统计进去。换句话说，桶有效地定义了文档集。除了桶本身，`bucket` 聚合同样计算返回每个桶有效的文档数量。

桶聚合，不同于 `metrics` 聚合，可以有子聚合。子聚合用来聚合父节点的桶聚合结果。

不同的桶聚合，有不同的聚合策略。有些定义单个桶，有的定义固定数量的多个桶，还有的在聚合过程中动态创建桶。

> `search.max_buckets` 集群设置限制了在单个响应中允许的桶数目。

### Terms aggregation

一个基于聚合的多桶值源，每个桶都是动态创建的——每个唯一值创建一个。

例如：

```
GET /_search
{
  "aggs": {
    "genres": {
      "terms": { "field": "genre" }
    }
  }
}
```

返回：

```json
{
  "aggregations": {
    "genres": {
      "doc_count_error_upper_bound": 0,
      "sum_other_doc_count": 0,
      "buckets": [
        {
          "key": "electronic",
          "doc_count": 6
        },
        {
          "key": "rock",
          "doc_count": 3
        },
        {
          "key": "jazz",
          "doc_count": 2
        }
      ]
    }
  }
}
```

1. `doc_count_error_upper_bound` 对于每一项在文档上的错误上限数量
2. `sum_other_doc_count` 当有特别多的唯一项时，`es` 只返回前几项；该值是所有没有包含在响应中的桶的其它文档的数量总和
3. `buckets` 前几项桶的列表，`top` 含义是根据排序定义的

`field` 可以是 关键词（Keyword）、数字（Numeric）、`ip`、`boolean` 或 `binary`。

> 默认情况下，在 `text` 字段上无法运行 `terms` 聚合。使用 `keyword` 类型的子字段（sub-field）代替。或者，在 `text` 字段上开启 `fielddata`，为字段分析的项（分词）创建桶。开启 `fielddata` 会显著地增加内存使用。

#### Size

默认，`terms` 聚合返回文档数最多的前 10 项。使用 `size` 参数以返回更多项，最多 `search.max_buckets` 限制。

如果数据包含 100 或者 1000 唯一项，提高 `terms` 聚合的 `size`，将它们全部返回。如果有更多的唯一项需要返回，使用聚合（composite）聚合代替。

更大的 `size` 使用更多的内存来计算，将整个聚合推至 `max_buckets` 限制。如果请求失败返回关于 `max_buckets` 的信息，那就是值给的太大了。

#### Shard size

为了获取更精准的结果，`terms` 聚合从每个分片（shard）中获取超过前 `size` 的项。获取前 `shard_size` 数量的项，默认为 `size * 1.5 + 10`。

这是为了解决这种情况，在一个分片上的一项有许多文档，但是比起其它的所有分片上 `size` 阈值数目的都小。如果每个分片只返回 `size` 项，聚合将返回该项的部分文档计数。所以 `terms` 返回更多项，尝试包含缺失的项。虽然有用，但仍可能返回一个项的部分文档。只是取了一个项的更分散的每个分片的文档数目。

*应该是每个分片只计算自己的某一项的数量，例如计算 `abc`，在分片 1 中有 100 个文档匹配，但在分片 2 中数量排不上前 `size` 名，所以分片 2 在返回中就不包含 `abc` 的数据了。为了避免这种情况，会多返回一些，平衡分布。*

提高 `shard_size` 可以更好计算这些分散的文档数量，并提高选择前几项项的准确性。比起提高 `size`，提高 `shard_size` 成本更小。然而，它仍然需要更多的字节，并在协调节点的内存等待。

> 本指导仅在使用 `terms` 聚合默认排序 `order` 时有效。如果不是按照文档数目倒序排列的其它方式排列，查看 Order。
>
> `shard_size` 不能小于 `size`（否则没有意义）。当真的小于时，`es` 会覆盖设置为等于 `size`。

#### Document count error

就算更大的 `shard_size` 值，`terms` 聚合的 `doc_count` 值也可能是近似的。导致，在这个 `terms` 聚合上的任何子聚合也是近似的。

`sum_other_doc_count` 是没有进入前 `size` 项的文档数量。如果值大于 `0`，那 `terms` 聚合肯定丢弃某些桶，不是由于没有匹配协调节点上的 `size` 就是没有匹配数据节点的 `shard_size`。

#### Per bucket document count error

如果将 `show_term_doc_count_error` 参数设置为 `true`，`terms` 聚合将包含 `doc_count_error_upper_bound`，这是每个分片返回的对于 `doc_count` 的错误上限数量。它是每个分片上没有进入 `shard_size` 的最大桶的数量之和。

更具体地说，设想在一个分片上有一个非常大的桶，但在其它分片被排除在 `shard_size` 外。那种情况下，`terms` 聚合会返回这个桶，因为它大，但是在一些分片上由于该项没有达到 `shard_size` 阈值，导致缺失了部分数据。`doc_count_error_upper_bound` 是这些丢失文档的最大数量。

```
GET /_search
  "aggs": {
    "products": {
      "terms": {
        "field": "product",
        "size": 5,
        "show_term_doc_count_error": true
      }
    }
  }
}
```

只有在项是通过文档数量倒序排列时，这些错误才可以被统计。当聚合根据项的值本身（正序或倒序）排列时，文档数量统计不会产生错误，因为如果某个分片没有返回出现在别的分片结果中的某一项，这个分片的索引中肯定没有那一项。当聚合根据子聚合排序或者文档数正序排列，文档计数中的错误无法被发现，并返回 -1 值表明。

#### Order

默认，`terms` 聚合根据文档 `_count` 倒序排序。这产生了 `es` 可以报告的有界文档计数错误。

可以使用 `order` 参数指定不同的排序顺序，但不推荐。创建一个项的（其它）排序是非常容易造成返回错误的结果，并且不容易发现。修改时要万分小心。

> 尤其要避免使用 `"order": { "_count": "asc" }`。如果要找稀有的项，使用 `rare_terms` 聚合代替。由于 `terms` 聚合从分片获取项的方式，采用正序文档数量排序常常会产生不正确的结果。

##### Ordering by the term value

